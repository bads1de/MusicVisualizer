{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "def create_particles(num_particles, width, height):\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(2, 5)\n",
    "        speed = np.random.randint(1, 5)\n",
    "        particles.append([x, y, size, speed])\n",
    "    return particles\n",
    "\n",
    "def update_particles(particles, width, height, energy):\n",
    "    for p in particles:\n",
    "        p[1] -= p[3] * energy  # Move up with speed influenced by energy\n",
    "        if p[1] < 0:\n",
    "            p[1] = height\n",
    "            p[0] = np.random.randint(0, width)\n",
    "    return particles\n",
    "\n",
    "def draw_particles(frame, particles, color):\n",
    "    for p in particles:\n",
    "        cv2.circle(frame, (int(p[0]), int(p[1])), p[2], color, -1)\n",
    "\n",
    "def create_mosaic_mask(height, width, num_blocks=30, min_block_size=20, max_block_size=150):\n",
    "    mask = np.ones((height, width), dtype=np.uint8) * 255\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        block_size = np.random.randint(min_block_size, max_block_size)\n",
    "        x = np.random.randint(0, width - block_size)\n",
    "        y = np.random.randint(0, height - block_size)\n",
    "        cv2.rectangle(mask, (x, y), (x + block_size, y + block_size), 0, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_mosaic_effect(frame, mask, block_size=30):\n",
    "    height, width = frame.shape[:2]\n",
    "    small = cv2.resize(frame, (width // block_size, height // block_size))\n",
    "    mosaic = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    return np.where(mask[:,:,None] == 255, frame, mosaic)\n",
    "\n",
    "def apply_blur_effect(frame, energy):\n",
    "    blur_amount = int(energy * 2)  \n",
    "    return cv2.GaussianBlur(frame, (blur_amount * 2 + 1, blur_amount * 2 + 1), 0)\n",
    "\n",
    "def apply_bounce_effect(frame, current_onset, max_onset):\n",
    "    bounce_amount = int(20 * current_onset / max_onset)  # 最大20ピクセルのバウンス\n",
    "    if bounce_amount > 0:\n",
    "        padded_frame = cv2.copyMakeBorder(frame, bounce_amount, bounce_amount, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        return padded_frame[bounce_amount:-bounce_amount, :]\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def create_music_visualizer(image_path, audio_path, output_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute the mel spectrogram and onset strength\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Create particles\n",
    "    particles = create_particles(100, width, height)\n",
    "\n",
    "    # Create a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('temp_output.mp4', fourcc, 30, (width, height))\n",
    "\n",
    "    # Calculate frames per audio chunk\n",
    "    chunk_size = sr // 30\n",
    "\n",
    "    # Initialize variables for smooth animation\n",
    "    prev_bars = np.zeros(64)\n",
    "    zoom_factor = 1.0\n",
    "\n",
    "    # Create mosaic mask with larger blocks randomly placed\n",
    "    mosaic_mask = create_mosaic_mask(height, width)\n",
    "\n",
    "    # Get max onset for normalization\n",
    "    max_onset = np.max(onset_env)\n",
    "\n",
    "    # Create the visualization\n",
    "    for i in range(0, len(y), chunk_size):\n",
    "        # Get the current audio chunk\n",
    "        chunk = y[i:i+chunk_size]\n",
    "\n",
    "        # Get the current spectrogram frame\n",
    "        spec_frame = S_dB[:, i//chunk_size] if i//chunk_size < S_dB.shape[1] else S_dB[:, -1]\n",
    "\n",
    "        # Get the current onset strength\n",
    "        current_onset = onset_env[i//chunk_size] if i//chunk_size < len(onset_env) else onset_env[-1]\n",
    "\n",
    "        # Calculate energy for particle movement and blur effect\n",
    "        energy = np.mean(np.abs(chunk)) * 10\n",
    "\n",
    "        # Create a copy of the image for this frame\n",
    "        frame = img.copy()\n",
    "\n",
    "        # Apply mosaic effect\n",
    "        frame = apply_mosaic_effect(frame, mosaic_mask)\n",
    "\n",
    "        # Update and draw particles\n",
    "        particles = update_particles(particles, width, height, energy)\n",
    "        draw_particles(frame, particles, (255, 255, 255))\n",
    "\n",
    "        # Draw the bars\n",
    "        bar_width = width // 64\n",
    "        max_bar_height = height // 2\n",
    "        for j, h in enumerate(spec_frame):\n",
    "            # Smooth the bar height\n",
    "            target_height = int(np.interp(h, [S_dB.min(), S_dB.max()], [0, max_bar_height]))\n",
    "            prev_bars[j] = prev_bars[j] * 0.7 + target_height * 0.3\n",
    "            bar_height = int(prev_bars[j])\n",
    "\n",
    "            # Draw semi-transparent bar\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height), \n",
    "                          ((j+1)*bar_width, height - bar_height), \n",
    "                          (255, 255, 255), \n",
    "                          -1)\n",
    "\n",
    "            # Draw bar outline\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height), \n",
    "                          ((j+1)*bar_width, height - bar_height), \n",
    "                          (200, 200, 200), \n",
    "                          2)\n",
    "\n",
    "        # Apply alpha blending for transparency\n",
    "        overlay = frame.copy()\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "\n",
    "        # Apply blur effect based on energy\n",
    "        frame = apply_blur_effect(frame, energy)\n",
    "\n",
    "        # Apply a rhythmic zoom effect\n",
    "        target_zoom = 1 + 0.05 * current_onset / max_onset\n",
    "        zoom_factor = zoom_factor * 0.7 + target_zoom * 0.3\n",
    "        scaled_frame = cv2.resize(frame, None, fx=zoom_factor, fy=zoom_factor)\n",
    "\n",
    "        # Crop the scaled frame to original size\n",
    "        start_y = (scaled_frame.shape[0] - height) // 2\n",
    "        start_x = (scaled_frame.shape[1] - width) // 2\n",
    "        frame = scaled_frame[start_y:start_y+height, start_x:start_x+width]\n",
    "\n",
    "        # Apply bounce effect\n",
    "        frame = apply_bounce_effect(frame, current_onset, max_onset)\n",
    "\n",
    "        # Write the frame\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Release the video writer\n",
    "    video.release()\n",
    "\n",
    "    # Add audio to the video using moviepy\n",
    "    video_clip = mpy.VideoFileClip(\"temp_output.mp4\")\n",
    "    audio_clip = mpy.AudioFileClip(audio_path)\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    # Clean up temporary file\n",
    "    import os\n",
    "    os.remove(\"temp_output.mp4\")\n",
    "\n",
    "# Usage\n",
    "image_path = 'image.png'\n",
    "audio_path = 'audio.mp3'\n",
    "output_path = 'output_video.mp4'\n",
    "\n",
    "create_music_visualizer(image_path, audio_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
