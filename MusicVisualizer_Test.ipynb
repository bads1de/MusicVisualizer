{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "\n",
    "def create_particles(num_particles, width, height):\n",
    "    \"\"\"\n",
    "    画面上にランダムなパーティクルを生成する関数\n",
    "\n",
    "    Args:\n",
    "        num_particles (int): 生成するパーティクルの数\n",
    "        width (int): 画面の幅\n",
    "        height (int): 画面の高さ\n",
    "\n",
    "    Returns:\n",
    "        list: パーティクルのリスト。各パーティクルは [x座標, y座標, サイズ, 速度] のリストとして表される\n",
    "    \"\"\"\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(2, 5)\n",
    "        speed = np.random.randint(1, 5)\n",
    "        particles.append([x, y, size, speed])\n",
    "    return particles\n",
    "\n",
    "def update_particles(particles, width, height, energy):\n",
    "    \"\"\"\n",
    "    パーティクルの位置を更新する関数\n",
    "\n",
    "    Args:\n",
    "        particles (list): パーティクルのリスト\n",
    "        width (int): 画面の幅\n",
    "        height (int): 画面の高さ\n",
    "        energy (float): 音声のエネルギー値 (0.0 - 1.0)\n",
    "\n",
    "    Returns:\n",
    "        list: 更新されたパーティクルのリスト\n",
    "    \"\"\"\n",
    "    for p in particles:\n",
    "        p[1] -= p[3] * energy  # パーティクルを下に移動させる\n",
    "        if p[1] < 0:  # 画面上部からはみ出したパーティクルを処理\n",
    "            p[1] = height\n",
    "            p[0] = np.random.randint(0, width)\n",
    "    return particles\n",
    "\n",
    "def draw_particles(frame, particles, color):\n",
    "    \"\"\"\n",
    "    パーティクルを描画する関数\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): 描画対象のフレーム\n",
    "        particles (list): パーティクルのリスト\n",
    "        color (tuple): パーティクルの色 (B, G, R)\n",
    "    \"\"\"\n",
    "    for p in particles:\n",
    "        cv2.circle(frame, (int(p[0]), int(p[1])), p[2], color, -1)  # パーティクルを描画\n",
    "\n",
    "def create_mosaic_mask(height, width, num_blocks=30, min_block_size=20, max_block_size=150):\n",
    "    \"\"\"\n",
    "    モザイク効果のためのマスクを生成する関数\n",
    "\n",
    "    Args:\n",
    "        height (int): マスクの高さ\n",
    "        width (int): マスクの幅\n",
    "        num_blocks (int, optional): モザイクブロックの数。デフォルトは30。\n",
    "        min_block_size (int, optional): モザイクブロックの最小サイズ。デフォルトは20。\n",
    "        max_block_size (int, optional): モザイクブロックの最大サイズ。デフォルトは150。\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: モザイクマスク\n",
    "    \"\"\"\n",
    "    mask = np.ones((height, width), dtype=np.uint8) * 255  # 白いマスクを作成\n",
    "    for _ in range(num_blocks):\n",
    "        block_size = np.random.randint(min_block_size, max_block_size)\n",
    "        x = np.random.randint(0, width - block_size)\n",
    "        y = np.random.randint(0, height - block_size)\n",
    "        cv2.rectangle(mask, (x, y), (x + block_size, y + block_size), 0, -1)  # ランダムな位置に黒い矩形を描画\n",
    "    return mask\n",
    "\n",
    "def apply_mosaic_effect(frame, mask, block_size=30):\n",
    "    \"\"\"\n",
    "    フレームにモザイク効果を適用する関数\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): 処理対象のフレーム\n",
    "        mask (numpy.ndarray): モザイクマスク\n",
    "        block_size (int, optional): モザイクブロックのサイズ。デフォルトは30。\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: モザイク効果が適用されたフレーム\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    small = cv2.resize(frame, (width // block_size, height // block_size))  # フレームを縮小\n",
    "    mosaic = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)  # 縮小したフレームを拡大\n",
    "    return np.where(mask[:,:,None] == 255, frame, mosaic)  # マスクに基づいてモザイク部分を適用\n",
    "\n",
    "def apply_blur_effect(frame, energy):\n",
    "    \"\"\"\n",
    "    フレームにブラー効果を適用する関数\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): 処理対象のフレーム\n",
    "        energy (float): 音声のエネルギー値 (0.0 - 1.0)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: ブラー効果が適用されたフレーム\n",
    "    \"\"\"\n",
    "    blur_amount = int(energy * 4)  # エネルギー値に基づいてブラーの強さを調整\n",
    "    return cv2.GaussianBlur(frame, (blur_amount * 2 + 1, blur_amount * 2 + 1), 0)  # ガウシアンブラーを適用\n",
    "\n",
    "def apply_bounce_effect(frame, current_onset, max_onset):\n",
    "    \"\"\"\n",
    "    フレームにバウンス効果を適用する関数\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): 処理対象のフレーム\n",
    "        current_onset (float): 現在のオンセット強度\n",
    "        max_onset (float): 最大オンセット強度\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: バウンス効果が適用されたフレーム\n",
    "    \"\"\"\n",
    "    bounce_amount = int(20 * current_onset / max_onset)  # オンセット強度に基づいてバウンスの高さを調整\n",
    "    if bounce_amount > 0:\n",
    "        padded_frame = cv2.copyMakeBorder(frame, bounce_amount, bounce_amount, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])  # フレームの上下に黒い領域を追加\n",
    "        return padded_frame[bounce_amount:-bounce_amount, :]  # バウンスしたように見える部分を切り出し\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def apply_glitch_effect(frame, strength=10):\n",
    "    \"\"\"\n",
    "    フレームにグリッチ効果を適用する関数\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): 処理対象のフレーム\n",
    "        strength (int, optional): グリッチの強さ。デフォルトは10。\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: グリッチ効果が適用されたフレーム\n",
    "    \"\"\"\n",
    "    height, width, _ = frame.shape\n",
    "    glitch_frame = frame.copy()\n",
    "    num_slices = np.random.randint(1, strength)  # グリッチの数をランダムに決定\n",
    "    for _ in range(num_slices):\n",
    "        slice_height = np.random.randint(1, height // strength)  # グリッチの高さ\n",
    "        start_y = np.random.randint(0, height - slice_height)  # グリッチの開始位置\n",
    "        start_x = np.random.randint(-strength, strength)  # グリッチの水平方向のずれ\n",
    "        end_x = width + start_x\n",
    "        if start_x > 0:\n",
    "            if end_x > width:\n",
    "                end_x = width\n",
    "            glitch_frame[start_y:start_y + slice_height, start_x:end_x] = frame[start_y:start_y + slice_height, :end_x - start_x]  # グリッチ部分をコピー\n",
    "        else:\n",
    "            if -start_x > width:\n",
    "                start_x = -width\n",
    "            glitch_frame[start_y:start_y + slice_height, :end_x] = frame[start_y:start_y + slice_height, -start_x:]  # グリッチ部分をコピー\n",
    "    return glitch_frame\n",
    "\n",
    "def create_music_visualizer(image_path, audio_path, output_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    # フレームレートを30に設定\n",
    "    fps = 30\n",
    "    n_frames = int(duration * fps)\n",
    "    \n",
    "    # メルスペクトログラムとオンセット強度の計算を改善\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=32, fmax=8000, hop_length=sr//fps)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=sr//fps)\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = img.shape\n",
    "    particles = create_particles(100, width, height)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('temp_output.mp4', fourcc, fps, (width, height))\n",
    "    \n",
    "    prev_bars = np.zeros(32)\n",
    "    zoom_factor = 1.0\n",
    "    mosaic_mask = create_mosaic_mask(height, width)\n",
    "    max_onset = np.max(onset_env)\n",
    "\n",
    "    for frame_num in range(n_frames):\n",
    "        # フレーム番号に基づいて音声データのインデックスを計算\n",
    "        audio_idx = int(frame_num * len(y) / n_frames)\n",
    "        chunk = y[audio_idx:audio_idx + sr//fps]\n",
    "        \n",
    "        spec_frame = S_dB[:, frame_num] if frame_num < S_dB.shape[1] else S_dB[:, -1]\n",
    "        current_onset = onset_env[frame_num] if frame_num < len(onset_env) else onset_env[-1]\n",
    "        energy = np.mean(np.abs(chunk)) * 10\n",
    "\n",
    "        frame = img.copy()\n",
    "        frame = apply_mosaic_effect(frame, mosaic_mask)\n",
    "        particles = update_particles(particles, width, height, energy)\n",
    "        draw_particles(frame, particles, (255, 255, 255))\n",
    "\n",
    "        bar_width = width // 32\n",
    "        max_bar_height = height // 4\n",
    "\n",
    "        for j, h in enumerate(spec_frame):\n",
    "            target_height = int(np.interp(h, [S_dB.min(), S_dB.max()], [0, max_bar_height]))\n",
    "            prev_bars[j] = prev_bars[j] * 0.7 + target_height * 0.3\n",
    "            bar_height = int(prev_bars[j])\n",
    "\n",
    "            bar_color = (255, 255, 255, 150)\n",
    "            outline_color = (0, 0, 0, 0)\n",
    "\n",
    "            # 上部のバー\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay,\n",
    "                          (j * bar_width, height // 2 - bar_height),\n",
    "                          ((j + 1) * bar_width, height // 2),\n",
    "                          bar_color,\n",
    "                          -1)\n",
    "            cv2.addWeighted(overlay, 0.5, frame, 1 - 0.5, 0, frame)\n",
    "            cv2.rectangle(frame,\n",
    "                          (j * bar_width, height // 2 - bar_height),\n",
    "                          ((j + 1) * bar_width, height // 2),\n",
    "                          outline_color,\n",
    "                          1)\n",
    "\n",
    "            # 下部のバー\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay,\n",
    "                          (j * bar_width, height // 2),\n",
    "                          ((j + 1) * bar_width, height // 2 + bar_height),\n",
    "                          bar_color,\n",
    "                          -1)\n",
    "            cv2.addWeighted(overlay, 0.5, frame, 1 - 0.5, 0, frame)\n",
    "            cv2.rectangle(frame,\n",
    "                          (j * bar_width, height // 2),\n",
    "                          ((j + 1) * bar_width, height // 2 + bar_height),\n",
    "                          outline_color,\n",
    "                          1)\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "        frame = apply_blur_effect(frame, energy)\n",
    "        target_zoom = 1 + 0.05 * current_onset / max_onset\n",
    "        zoom_factor = zoom_factor * 0.7 + target_zoom * 0.3\n",
    "        scaled_frame = cv2.resize(frame, None, fx=zoom_factor, fy=zoom_factor)\n",
    "        start_y = (scaled_frame.shape[0] - height) // 2\n",
    "        start_x = (scaled_frame.shape[1] - width) // 2\n",
    "        frame = scaled_frame[start_y:start_y + height, start_x:start_x + width]\n",
    "        frame = apply_bounce_effect(frame, current_onset, max_onset)\n",
    "        if np.random.rand() < 0.1:\n",
    "            frame = apply_glitch_effect(frame)\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    video.release()\n",
    "    video_clip = mpy.VideoFileClip(\"temp_output.mp4\")\n",
    "    audio_clip = mpy.AudioFileClip(audio_path)\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    import os\n",
    "    os.remove(\"temp_output.mp4\")\n",
    "\n",
    "# 使用例\n",
    "image_path = 'image.png'\n",
    "audio_path = 'audio.mp3'\n",
    "output_path = 'output_videoDemo.mp4'\n",
    "create_music_visualizer(image_path, audio_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import cv2\n",
    "import dlib\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "def create_particles(num_particles, width, height):\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(2, 5)\n",
    "        speed = np.random.randint(1, 5)\n",
    "        particles.append([x, y, size, speed])\n",
    "    return particles\n",
    "\n",
    "def update_particles(particles, width, height, energy):\n",
    "    for p in particles:\n",
    "        p[1] -= p[3] * energy\n",
    "        if p[1] < 0:\n",
    "            p[1] = height\n",
    "            p[0] = np.random.randint(0, width)\n",
    "    return particles\n",
    "\n",
    "def draw_particles(frame, particles, color):\n",
    "    for p in particles:\n",
    "        cv2.circle(frame, (int(p[0]), int(p[1])), p[2], color, -1)\n",
    "\n",
    "def create_mosaic_mask(height, width, faces, num_blocks=50, min_block_size=20, max_block_size=150):\n",
    "    mask = np.ones((height, width), dtype=np.uint8) * 255\n",
    "    for _ in range(num_blocks):\n",
    "        block_size = np.random.randint(min_block_size, max_block_size)\n",
    "        x = np.random.randint(0, width - block_size)\n",
    "        y = np.random.randint(0, height - block_size)\n",
    "        block_rect = (x, y, x + block_size, y + block_size)\n",
    "\n",
    "        face_collision = any([x < face.right() and x + block_size > face.left() and y < face.bottom() and y + block_size > face.top() for face in faces])\n",
    "        if not face_collision:\n",
    "            cv2.rectangle(mask, (x, y), (x + block_size, y + block_size), 0, -1)\n",
    "    return mask\n",
    "\n",
    "def apply_mosaic_effect(frame, mask, block_size=30):\n",
    "    height, width = frame.shape[:2]\n",
    "    small = cv2.resize(frame, (width // block_size, height // block_size))\n",
    "    mosaic = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    return np.where(mask[:,:,None] == 255, frame, mosaic)\n",
    "\n",
    "def apply_blur_effect(frame, energy):\n",
    "    blur_amount = int(energy * 4)\n",
    "    return cv2.GaussianBlur(frame, (blur_amount * 2 + 1, blur_amount * 2 + 1), 0)\n",
    "\n",
    "def apply_bounce_effect(frame, current_onset, max_onset):\n",
    "    bounce_amount = int(20 * current_onset / max_onset)\n",
    "    if bounce_amount > 0:\n",
    "        padded_frame = cv2.copyMakeBorder(frame, bounce_amount, bounce_amount, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        return padded_frame[bounce_amount:-bounce_amount, :]\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def apply_glitch_effect(frame, strength=10):\n",
    "    height, width, _ = frame.shape\n",
    "    glitch_frame = frame.copy()\n",
    "    num_slices = np.random.randint(1, strength)\n",
    "    for _ in range(num_slices):\n",
    "        slice_height = np.random.randint(1, height // strength)\n",
    "        start_y = np.random.randint(0, height - slice_height)\n",
    "        start_x = np.random.randint(-strength, strength)\n",
    "        end_x = width + start_x\n",
    "        if start_x > 0:\n",
    "            if end_x > width:\n",
    "                end_x = width\n",
    "            glitch_frame[start_y:start_y + slice_height, start_x:end_x] = frame[start_y:start_y + slice_height, :end_x - start_x]\n",
    "        else:\n",
    "            if -start_x > width:\n",
    "                start_x = -width\n",
    "            glitch_frame[start_y:start_y + slice_height, :end_x] = frame[start_y:start_y + slice_height, -start_x:]\n",
    "    return glitch_frame\n",
    "\n",
    "def create_music_visualizer(image_path, audio_path, output_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    fps = 30\n",
    "    n_frames = int(duration * fps)\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=32, fmax=8000, hop_length=sr//fps)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=sr//fps)\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    faces = detector(img, 1)\n",
    "    \n",
    "    particles = create_particles(100, width, height)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('temp_output.mp4', fourcc, fps, (width, height))\n",
    "    \n",
    "    prev_bars = np.zeros(32)\n",
    "    zoom_factor = 1.0\n",
    "    max_onset = np.max(onset_env)\n",
    "\n",
    "    mosaic_mask = create_mosaic_mask(height, width, faces)\n",
    "\n",
    "    for frame_num in range(n_frames):\n",
    "        audio_idx = int(frame_num * len(y) / n_frames)\n",
    "        chunk = y[audio_idx:audio_idx + sr//fps]\n",
    "        \n",
    "        spec_frame = S_dB[:, frame_num] if frame_num < S_dB.shape[1] else S_dB[:, -1]\n",
    "        current_onset = onset_env[frame_num] if frame_num < len(onset_env) else onset_env[-1]\n",
    "        energy = np.mean(np.abs(chunk)) * 10\n",
    "\n",
    "        frame = img.copy()\n",
    "        frame = apply_mosaic_effect(frame, mosaic_mask)\n",
    "        particles = update_particles(particles, width, height, energy)\n",
    "        draw_particles(frame, particles, (255, 255, 255))\n",
    "\n",
    "        bar_width = width // 32\n",
    "        max_bar_height = height // 4\n",
    "\n",
    "        for j, h in enumerate(spec_frame):\n",
    "            target_height = int(np.interp(h, [S_dB.min(), S_dB.max()], [0, max_bar_height]))\n",
    "            prev_bars[j] = prev_bars[j] * 0.7 + target_height * 0.3\n",
    "            bar_height = int(prev_bars[j])\n",
    "\n",
    "            bar_color = (255, 255, 255, 150)\n",
    "\n",
    "            # 上部のバー\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay,\n",
    "                          (j * bar_width, height // 2 - bar_height),\n",
    "                          ((j + 1) * bar_width, height // 2),\n",
    "                          bar_color,\n",
    "                          -1)\n",
    "            cv2.addWeighted(overlay, 0.5, frame, 1 - 0.5, 0, frame)\n",
    "\n",
    "            # 下部のバー\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay,\n",
    "                          (j * bar_width, height // 2),\n",
    "                          ((j + 1) * bar_width, height // 2 + bar_height),\n",
    "                          bar_color,\n",
    "                          -1)\n",
    "            cv2.addWeighted(overlay, 0.5, frame, 1 - 0.5, 0, frame)\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "        frame = apply_blur_effect(frame, energy)\n",
    "        target_zoom = 1 + 0.05 * current_onset / max_onset\n",
    "        zoom_factor = zoom_factor * 0.7 + target_zoom * 0.3\n",
    "        scaled_frame = cv2.resize(frame, None, fx=zoom_factor, fy=zoom_factor)\n",
    "        start_y = (scaled_frame.shape[0] - height) // 2\n",
    "        start_x = (scaled_frame.shape[1] - width) // 2\n",
    "        frame = scaled_frame[start_y:start_y + height, start_x:start_x + width]\n",
    "        frame = apply_bounce_effect(frame, current_onset, max_onset)\n",
    "        if np.random.rand() < 0.1:\n",
    "            frame = apply_glitch_effect(frame)\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    video.release()\n",
    "    \n",
    "    video = mpy.VideoFileClip('temp_output.mp4')\n",
    "    audio = mpy.AudioFileClip(audio_path).set_duration(video.duration)\n",
    "    final_video = video.set_audio(audio)\n",
    "    final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "image_path = 'image.png'\n",
    "audio_path = 'audio.mp3'\n",
    "output_path = 'output_videoDemo.mp4'\n",
    "create_music_visualizer(image_path, audio_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
