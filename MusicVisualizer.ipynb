{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Music Visualizer main\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "def create_particles(num_particles, width, height):\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(2, 5)\n",
    "        speed = np.random.randint(1, 5)\n",
    "        particles.append([x, y, size, speed])\n",
    "    return particles\n",
    "\n",
    "def update_particles(particles, width, height, energy):\n",
    "    for p in particles:\n",
    "        p[1] -= p[3] * energy  # Move up with speed influenced by energy\n",
    "        if p[1] < 0:\n",
    "            p[1] = height\n",
    "            p[0] = np.random.randint(0, width)\n",
    "    return particles\n",
    "\n",
    "def draw_particles(frame, particles, color):\n",
    "    for p in particles:\n",
    "        cv2.circle(frame, (int(p[0]), int(p[1])), p[2], color, -1)\n",
    "\n",
    "def create_mosaic_mask(height, width, num_blocks=30, min_block_size=20, max_block_size=150):\n",
    "    mask = np.ones((height, width), dtype=np.uint8) * 255\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        block_size = np.random.randint(min_block_size, max_block_size)\n",
    "        x = np.random.randint(0, width - block_size)\n",
    "        y = np.random.randint(0, height - block_size)\n",
    "        cv2.rectangle(mask, (x, y), (x + block_size, y + block_size), 0, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_mosaic_effect(frame, mask, block_size=30):\n",
    "    height, width = frame.shape[:2]\n",
    "    small = cv2.resize(frame, (width // block_size, height // block_size))\n",
    "    mosaic = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    return np.where(mask[:,:,None] == 255, frame, mosaic)\n",
    "\n",
    "def apply_blur_effect(frame, energy):\n",
    "    blur_amount = int(energy * 2)  \n",
    "    return cv2.GaussianBlur(frame, (blur_amount * 2 + 1, blur_amount * 2 + 1), 0)\n",
    "\n",
    "def apply_bounce_effect(frame, current_onset, max_onset):\n",
    "    bounce_amount = int(20 * current_onset / max_onset)  # 最大20ピクセルのバウンス\n",
    "    if bounce_amount > 0:\n",
    "        padded_frame = cv2.copyMakeBorder(frame, bounce_amount, bounce_amount, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        return padded_frame[bounce_amount:-bounce_amount, :]\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def create_music_visualizer(image_path, audio_path, output_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute the mel spectrogram and onset strength\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Create particles\n",
    "    particles = create_particles(100, width, height)\n",
    "\n",
    "    # Create a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('temp_output.mp4', fourcc, 30, (width, height))\n",
    "\n",
    "    # Calculate frames per audio chunk\n",
    "    chunk_size = sr // 30\n",
    "\n",
    "    # Initialize variables for smooth animation\n",
    "    prev_bars = np.zeros(64)\n",
    "    zoom_factor = 1.0\n",
    "\n",
    "    # Create mosaic mask with larger blocks randomly placed\n",
    "    mosaic_mask = create_mosaic_mask(height, width)\n",
    "\n",
    "    # Get max onset for normalization\n",
    "    max_onset = np.max(onset_env)\n",
    "\n",
    "    # Create the visualization\n",
    "    for i in range(0, len(y), chunk_size):\n",
    "        # Get the current audio chunk\n",
    "        chunk = y[i:i+chunk_size]\n",
    "\n",
    "        # Get the current spectrogram frame\n",
    "        spec_frame = S_dB[:, i//chunk_size] if i//chunk_size < S_dB.shape[1] else S_dB[:, -1]\n",
    "\n",
    "        # Get the current onset strength\n",
    "        current_onset = onset_env[i//chunk_size] if i//chunk_size < len(onset_env) else onset_env[-1]\n",
    "\n",
    "        # Calculate energy for particle movement and blur effect\n",
    "        energy = np.mean(np.abs(chunk)) * 10\n",
    "\n",
    "        # Create a copy of the image for this frame\n",
    "        frame = img.copy()\n",
    "\n",
    "        # Apply mosaic effect\n",
    "        frame = apply_mosaic_effect(frame, mosaic_mask)\n",
    "\n",
    "        # Update and draw particles\n",
    "        particles = update_particles(particles, width, height, energy)\n",
    "        draw_particles(frame, particles, (255, 255, 255))\n",
    "\n",
    "        # Draw the bars\n",
    "        bar_width = width // 64\n",
    "        max_bar_height = height // 2\n",
    "        for j, h in enumerate(spec_frame):\n",
    "            # Smooth the bar height\n",
    "            target_height = int(np.interp(h, [S_dB.min(), S_dB.max()], [0, max_bar_height]))\n",
    "            prev_bars[j] = prev_bars[j] * 0.7 + target_height * 0.3\n",
    "            bar_height = int(prev_bars[j])\n",
    "\n",
    "            # Draw semi-transparent bar\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height), \n",
    "                          ((j+1)*bar_width, height - bar_height), \n",
    "                          (255, 255, 255), \n",
    "                          -1)\n",
    "\n",
    "            # Draw bar outline\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height), \n",
    "                          ((j+1)*bar_width, height - bar_height), \n",
    "                          (200, 200, 200), \n",
    "                          2)\n",
    "\n",
    "        # Apply alpha blending for transparency\n",
    "        overlay = frame.copy()\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "\n",
    "        # Apply blur effect based on energy\n",
    "        frame = apply_blur_effect(frame, energy)\n",
    "\n",
    "        # Apply a rhythmic zoom effect\n",
    "        target_zoom = 1 + 0.05 * current_onset / max_onset\n",
    "        zoom_factor = zoom_factor * 0.7 + target_zoom * 0.3\n",
    "        scaled_frame = cv2.resize(frame, None, fx=zoom_factor, fy=zoom_factor)\n",
    "\n",
    "        # Crop the scaled frame to original size\n",
    "        start_y = (scaled_frame.shape[0] - height) // 2\n",
    "        start_x = (scaled_frame.shape[1] - width) // 2\n",
    "        frame = scaled_frame[start_y:start_y+height, start_x:start_x+width]\n",
    "\n",
    "        # Apply bounce effect\n",
    "        frame = apply_bounce_effect(frame, current_onset, max_onset)\n",
    "\n",
    "        # Write the frame\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Release the video writer\n",
    "    video.release()\n",
    "\n",
    "    # Add audio to the video using moviepy\n",
    "    video_clip = mpy.VideoFileClip(\"temp_output.mp4\")\n",
    "    audio_clip = mpy.AudioFileClip(audio_path)\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    # Clean up temporary file\n",
    "    import os\n",
    "    os.remove(\"temp_output.mp4\")\n",
    "\n",
    "# Usage\n",
    "image_path = 'image.png'\n",
    "audio_path = 'audio.mp3'\n",
    "output_path = 'output_video.mp4'\n",
    "\n",
    "create_music_visualizer(image_path, audio_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] プロセスはファイルにアクセスできません。別のプロセスが使用中です。: 'temp_output.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 383\u001b[0m\n\u001b[0;32m    380\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    381\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 383\u001b[0m \u001b[43mcreate_music_visualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 376\u001b[0m, in \u001b[0;36mcreate_music_visualizer\u001b[1;34m(image_path, audio_path, output_path)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Clean up temporary file\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemp_output.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] プロセスはファイルにアクセスできません。別のプロセスが使用中です。: 'temp_output.mp4'"
     ]
    }
   ],
   "source": [
    "#Music Visualizer test\n",
    "import numpy as np\n",
    "import librosa\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "def create_particles(num_particles, width, height):\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        size = np.random.randint(2, 5)\n",
    "        speed = np.random.randint(1, 5)\n",
    "        particles.append([x, y, size, speed])\n",
    "    return particles\n",
    "\n",
    "def update_particles(particles, width, height, energy):\n",
    "    for p in particles:\n",
    "        p[1] -= p[3] * energy  # Move up with speed influenced by energy\n",
    "        if p[1] < 0:\n",
    "            p[1] = height\n",
    "            p[0] = np.random.randint(0, width)\n",
    "    return particles\n",
    "\n",
    "def draw_particles(frame, particles, color):\n",
    "    for p in particles:\n",
    "        cv2.circle(frame, (int(p[0]), int(p[1])), p[2], color, -1)\n",
    "\n",
    "def create_mosaic_mask(height, width, num_blocks=30, min_block_size=20, max_block_size=150):\n",
    "    mask = np.ones((height, width), dtype=np.uint8) * 255\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        block_size = np.random.randint(min_block_size, max_block_size)\n",
    "        x = np.random.randint(0, width - block_size)\n",
    "        y = np.random.randint(0, height - block_size)\n",
    "        cv2.rectangle(mask, (x, y), (x + block_size, y + block_size), 0, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def apply_mosaic_effect(frame, mask, block_size=30):\n",
    "    height, width = frame.shape[:2]\n",
    "    small = cv2.resize(frame, (width // block_size, height // block_size))\n",
    "    mosaic = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    return np.where(mask[:,:,None] == 255, frame, mosaic)\n",
    "\n",
    "def apply_blur_effect(frame, energy):\n",
    "    blur_amount = int(energy * 2)  \n",
    "    return cv2.GaussianBlur(frame, (blur_amount * 2 + 1, blur_amount * 2 + 1), 0)\n",
    "\n",
    "def apply_bounce_effect(frame, current_onset, max_onset):\n",
    "    bounce_amount = int(20 * current_onset / max_onset)  # 最大20ピクセルのバウンス\n",
    "    if bounce_amount > 0:\n",
    "        padded_frame = cv2.copyMakeBorder(frame, bounce_amount, bounce_amount, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        return padded_frame[bounce_amount:-bounce_amount, :]\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def apply_glitch_effect(frame, strength=10):\n",
    "    height, width, _ = frame.shape\n",
    "    glitch_frame = frame.copy()\n",
    "    num_slices = np.random.randint(1, strength)\n",
    "    for _ in range(num_slices):\n",
    "        slice_height = np.random.randint(1, height // strength)\n",
    "        start_y = np.random.randint(0, height - slice_height)\n",
    "        start_x = np.random.randint(-strength, strength)\n",
    "        end_x = width + start_x\n",
    "        if start_x > 0:\n",
    "            if end_x > width:\n",
    "                end_x = width\n",
    "            glitch_frame[start_y:start_y + slice_height, start_x:end_x] = frame[start_y:start_y + slice_height, :end_x - start_x]\n",
    "        else:\n",
    "            if -start_x > width:\n",
    "                start_x = -width\n",
    "            glitch_frame[start_y:start_y + slice_height, :end_x] = frame[start_y:start_y + slice_height, -start_x:]\n",
    "    return glitch_frame\n",
    "\n",
    "def create_music_visualizer(image_path, audio_path, output_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute the mel spectrogram and onset strength\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Create particles\n",
    "    particles = create_particles(100, width, height)\n",
    "\n",
    "    # Create a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('temp_output.mp4', fourcc, 30, (width, height))\n",
    "\n",
    "    # Calculate frames per audio chunk\n",
    "    chunk_size = sr // 30\n",
    "\n",
    "    # Initialize variables for smooth animation\n",
    "    prev_bars = np.zeros(64)\n",
    "    zoom_factor = 1.0\n",
    "\n",
    "    # Create mosaic mask with larger blocks randomly placed\n",
    "    mosaic_mask = create_mosaic_mask(height, width)\n",
    "\n",
    "    # Get max onset for normalization\n",
    "    max_onset = np.max(onset_env)\n",
    "\n",
    "    # Create the visualization\n",
    "    for i in range(0, len(y), chunk_size):\n",
    "        # Get the current audio chunk\n",
    "        chunk = y[i:i+chunk_size]\n",
    "\n",
    "        # Get the current spectrogram frame\n",
    "        spec_frame = S_dB[:, i//chunk_size] if i//chunk_size < S_dB.shape[1] else S_dB[:, -1]\n",
    "\n",
    "        # Get the current onset strength\n",
    "        current_onset = onset_env[i//chunk_size] if i//chunk_size < len(onset_env) else onset_env[-1]\n",
    "\n",
    "        # Calculate energy for particle movement and blur effect\n",
    "        energy = np.mean(np.abs(chunk)) * 10\n",
    "\n",
    "        # Create a copy of the image for this frame\n",
    "        frame = img.copy()\n",
    "\n",
    "        # Apply mosaic effect\n",
    "        frame = apply_mosaic_effect(frame, mosaic_mask)\n",
    "\n",
    "        # Update and draw particles\n",
    "        particles = update_particles(particles, width, height, energy)\n",
    "        draw_particles(frame, particles, (255, 255, 255))\n",
    "\n",
    "        # Draw the bars\n",
    "        bar_width = width // 64\n",
    "        max_bar_height = height // 4  # Reduced to 1/4 of the original height\n",
    "        for j, h in enumerate(spec_frame):\n",
    "            # Smooth the bar height\n",
    "            target_height = int(np.interp(h, [S_dB.min(), S_dB.max()], [0, max_bar_height]))\n",
    "            prev_bars[j] = prev_bars[j] * 0.7 + target_height * 0.3\n",
    "            bar_height = int(prev_bars[j])\n",
    "\n",
    "            # Calculate gradient colors\n",
    "            start_color = (50, 50, 200)  # Dark blue\n",
    "            end_color = (200, 50, 50)    # Dark red\n",
    "            r = int(np.interp(bar_height, [0, max_bar_height], [start_color[0], end_color[0]]))\n",
    "            g = int(np.interp(bar_height, [0, max_bar_height], [start_color[1], end_color[1]]))\n",
    "            b = int(np.interp(bar_height, [0, max_bar_height], [start_color[2], end_color[2]]))\n",
    "\n",
    "            # Draw rounded rectangle for the bar\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height), \n",
    "                          ((j+1)*bar_width, height - bar_height), \n",
    "                          (r, g, b), \n",
    "                          -1)\n",
    "\n",
    "            # Add glowing effect\n",
    "            glow_color = (min(r + 50, 255), min(g + 50, 255), min(b + 50, 255))\n",
    "            cv2.rectangle(frame, \n",
    "                          (j*bar_width, height - bar_height), \n",
    "                          ((j+1)*bar_width, height - bar_height + 5), \n",
    "                          glow_color, \n",
    "                          -1)\n",
    "\n",
    "            # Add reflection\n",
    "            reflection_height = bar_height // 2\n",
    "            reflection = frame[height - bar_height:height, j*bar_width:(j+1)*bar_width]\n",
    "            reflection = cv2.flip(reflection, 0)\n",
    "            reflection = cv2.addWeighted(reflection, 0.3, np.zeros_like(reflection), 0.7, 0)\n",
    "            frame[height:height + reflection_height, j*bar_width:(j+1)*bar_width] = reflection[:reflection_height]\n",
    "\n",
    "        # Apply alpha blending for transparency\n",
    "        overlay = frame.copy()\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "\n",
    "        # Apply blur effect based on energy\n",
    "        frame = apply_blur_effect(frame, energy)\n",
    "\n",
    "        # Apply a rhythmic zoom effect\n",
    "        target_zoom = 1 + 0.05 * current_onset / max_onset\n",
    "        zoom_factor = zoom_factor * 0.7 + target_zoom * 0.3\n",
    "        scaled_frame = cv2.resize(frame, None, fx=zoom_factor, fy=zoom_factor)\n",
    "\n",
    "        # Crop the scaled frame to original size\n",
    "        start_y = (scaled_frame.shape[0] - height) // 2\n",
    "        start_x = (scaled_frame.shape[1] - width) // 2\n",
    "        frame = scaled_frame[start_y:start_y+height, start_x:start_x+width]\n",
    "\n",
    "        # Apply bounce effect\n",
    "        frame = apply_bounce_effect(frame, current_onset, max_onset)\n",
    "\n",
    "        # Apply glitch effect randomly with a low probability\n",
    "        if np.random.rand() < 0.1:\n",
    "            frame = apply_glitch_effect(frame)\n",
    "\n",
    "        # Write the frame\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Release the video writer\n",
    "    video.release()\n",
    "\n",
    "    # Add audio to the video using moviepy\n",
    "    video_clip = mpy.VideoFileClip(\"temp_output.mp4\")\n",
    "    audio_clip = mpy.AudioFileClip(audio_path)\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    # Clean up temporary file\n",
    "    import os\n",
    "    os.remove(\"temp_output.mp4\")\n",
    "\n",
    "# Usage\n",
    "image_path = 'image.png'\n",
    "audio_path = 'audio.mp3'\n",
    "output_path = 'output_video.mp4'\n",
    "\n",
    "create_music_visualizer(image_path, audio_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
